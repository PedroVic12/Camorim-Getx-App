{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jhs4ShflNQAD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### depedences"
      ],
      "metadata": {
        "id": "LtERrGOWNWu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install PyPDF2 pandas  deep_translator langdetect numpy scikit-learn matplotlib"
      ],
      "metadata": {
        "id": "I-PlabwtNRuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xAzZpN3WT5O0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo de uso ML"
      ],
      "metadata": {
        "id": "yc4Nq2g6T8qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import graphviz\n",
        "\n",
        "# Carregando o conjunto de dados Iris\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "iris_df['species'] = iris.target\n",
        "\n",
        "# Dividindo os dados em características (X) e rótulos (y)\n",
        "X = iris_df.drop('species', axis=1)\n",
        "y = iris_df['species']\n",
        "\n",
        "# Dividindo os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Modelo 1: Árvore de Decisão com critério 'gini'\n",
        "model_gini = DecisionTreeClassifier(criterion='gini')\n",
        "model_gini.fit(X_train, y_train)\n",
        "predictions_gini = model_gini.predict(X_test)\n",
        "accuracy_gini = accuracy_score(y_test, predictions_gini)\n",
        "\n",
        "# Modelo 2: Árvore de Decisão com critério 'entropy'\n",
        "model_entropy = DecisionTreeClassifier(criterion='entropy')\n",
        "model_entropy.fit(X_train, y_train)\n",
        "predictions_entropy = model_entropy.predict(X_test)\n",
        "accuracy_entropy = accuracy_score(y_test, predictions_entropy)\n",
        "\n",
        "\n",
        "\n",
        "display(X)\n",
        "print(y)\n",
        "print(accuracy_gini, accuracy_entropy)  # Exibe a precisão de ambos os modelos\n",
        "\n",
        "# Exportar a árvore de decisão para um arquivo dot\n",
        "dot_data = export_graphviz(model_entropy, out_file=None,\n",
        "                           feature_names=iris.feature_names,\n",
        "                           class_names=iris.target_names,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "# Criar gráfico e visualizar\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"iris_decision_tree\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "fblRvZp9T4Bj",
        "outputId": "71b5eacc-13ec-44c7-f864-da5290e931d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
              "0                  5.1               3.5                1.4               0.2\n",
              "1                  4.9               3.0                1.4               0.2\n",
              "2                  4.7               3.2                1.3               0.2\n",
              "3                  4.6               3.1                1.5               0.2\n",
              "4                  5.0               3.6                1.4               0.2\n",
              "..                 ...               ...                ...               ...\n",
              "145                6.7               3.0                5.2               2.3\n",
              "146                6.3               2.5                5.0               1.9\n",
              "147                6.5               3.0                5.2               2.0\n",
              "148                6.2               3.4                5.4               2.3\n",
              "149                5.9               3.0                5.1               1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d616465-097a-4845-bc0e-986acc4adb49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d616465-097a-4845-bc0e-986acc4adb49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d616465-097a-4845-bc0e-986acc4adb49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d616465-097a-4845-bc0e-986acc4adb49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bca3006d-996d-40da-a372-9df030456d2a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bca3006d-996d-40da-a372-9df030456d2a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bca3006d-996d-40da-a372-9df030456d2a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "145    2\n",
            "146    2\n",
            "147    2\n",
            "148    2\n",
            "149    2\n",
            "Name: species, Length: 150, dtype: int64\n",
            "1.0 0.9777777777777777\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'iris_decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pypltot as plt\n",
        "\n",
        "class ModeloPreditivoCamorim:\n",
        "    def __init__(self):\n",
        "        # Inicializando o modelo de árvore de decisão\n",
        "        self.model = DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "    def tokenText(self):\n",
        "        \"\"\"       Converta o texto das \"Medidas de Segurança\" e das \"Ações de Manutenção\" em um formato numérico utilizando uma técnica como CountVectorizer do scikit-learn. Isso transformará seu texto em um conjunto de características baseadas na frequência das palavras.\"\"\"\n",
        "        pass\n",
        "    def mapTextItens(self):\n",
        "        \"\"\" Atribua rótulos a cada exemplo de texto. Por exemplo, você pode usar 0 para \"Medidas de Segurança\" e 1 para \"Ações de Manutenção\". \"\"\"\n",
        "        pass\n",
        "\n",
        "    def extrarInfoRegex(self):\n",
        "\n",
        "    def train(self, X, y):\n",
        "        # Treinando o modelo com os dados fornecidos\n",
        "        self.model.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Realizando previsões com o modelo treinado\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        # Avaliando a precisão do modelo\n",
        "        predictions = self.predict(X)\n",
        "        plt.plot(X,y)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n"
      ],
      "metadata": {
        "id": "9Oe3PN0cRGwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Exemplo de uso\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 5)  # 100 amostras, 5 características\n",
        "y = np.random.randint(2, size=100)  # 100 rótulos binários\n",
        "\n",
        "# Dividindo os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Instanciando e utilizando a classe SimplePredictiveModel\n",
        "model = ModeloPreditivoCamorim()\n",
        "model.train(X_train, y_train)\n",
        "accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(accuracy)  # Exibe a precisão do modelo no conjunto de teste\n"
      ],
      "metadata": {
        "id": "di6bUId9RJBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL"
      ],
      "metadata": {
        "id": "jhs4ShflNQAD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFJhCnqPNJl5"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader, PdfFileWriter, PdfFileReader\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "from PIL import Image\n",
        "from deep_translator import GoogleTranslator\n",
        "from langdetect import detect\n",
        "\n",
        "\n",
        "class Dragonite:\n",
        "    def __init__(self, path):\n",
        "        self.reader = PdfReader(path)\n",
        "        self.number_of_pages = len(self.reader.pages)\n",
        "\n",
        "\n",
        "\n",
        "    #! Metodos de tradução\n",
        "    def traduzirTexto(self, texto_em_ingles):\n",
        "        texto_traduzido = GoogleTranslator(source='en', target='pt').translate(texto_em_ingles) # use translate_text here\n",
        "        return texto_traduzido\n",
        "\n",
        "    def is_english(self, text):\n",
        "        try:\n",
        "            # Se detectar que o idioma é inglês, retorna True\n",
        "            return detect(text) == 'en'\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def maybe_translate(self, text):\n",
        "        # Verifica se o texto é em inglês\n",
        "        if self.is_english(text):\n",
        "            # Traduz o texto\n",
        "            print('\\n\\n\\nTraduzindo texto...')\n",
        "            return self.traduzirTexto(text)\n",
        "        # Retorna o texto original se não for inglês\n",
        "        return text\n",
        "\n",
        "    #!Metodos PDF\n",
        "    def split_pdf(self, output_directory=\"./\"):\n",
        "        \"\"\"\n",
        "        Split the original PDF into multiple one-page PDFs.\n",
        "        \"\"\"\n",
        "        if not output_directory.endswith(\"/\"):\n",
        "            output_directory += \"/\"\n",
        "\n",
        "        inputpdf = PdfFileReader(open(self.reader.stream.name, \"rb\"))\n",
        "        for i in range(inputpdf.numPages):\n",
        "            output = PdfFileWriter()\n",
        "            output.addPage(inputpdf.getPage(i))\n",
        "            with open(output_directory + f\"pdf_{i+1}.pdf\", \"wb\") as output_stream:\n",
        "                output.write(output_stream)\n",
        "\n",
        "        return [output_directory + f\"pdf_{i+1}.pdf\" for i in range(inputpdf.numPages)]\n",
        "\n",
        "    def pdf_to_image(self, pdf_path, output_directory=\"./\"):\n",
        "        \"\"\"\n",
        "        Convert a PDF file to JPEG images.\n",
        "        \"\"\"\n",
        "        if not output_directory.endswith(\"/\"):\n",
        "            output_directory += \"/\"\n",
        "\n",
        "        # Convert PDF to images\n",
        "        images = Image.open(pdf_path)\n",
        "        image_paths = []\n",
        "        for i, image in enumerate(images):\n",
        "            image_path = output_directory + f\"image_{i+1}.jpeg\"\n",
        "            image.save(image_path, \"JPEG\")\n",
        "            image_paths.append(image_path)\n",
        "\n",
        "        return image_paths\n",
        "\n",
        "    def ler_pagina(self, page_number):\n",
        "        page_number -= 1\n",
        "        if 0 <= page_number < self.number_of_pages:\n",
        "            return self.reader.pages[page_number].extract_text()\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def ler_intervalo_paginas(self, inicio, fim):\n",
        "        \"\"\"\n",
        "        Lê um intervalo de páginas do PDF e retorna o texto concatenado.\n",
        "\n",
        "        :param inicio: Número da página inicial.\n",
        "        :param fim: Número da página final.\n",
        "        :return: Texto concatenado das páginas.\n",
        "        \"\"\"\n",
        "        texto_total = \"\"\n",
        "        for pagina in range(inicio, fim+1):  # fim+1 para incluir a última página no intervalo\n",
        "            texto_total += self.ler_pagina(pagina)\n",
        "        return texto_total\n",
        "\n",
        "\n",
        "    #! Métodos Regex\n",
        "\n",
        "    \"\"\"\n",
        "    A função split_text é usada para dividir o texto por equipamento, mas parece que está fazendo a divisão com base no caractere '\\n' apenas.\n",
        "    A função group_by_equipment parece ser onde a mágica acontece. Ela tenta agrupar as informações por equipamento.\n",
        "    \"\"\"\n",
        "\n",
        "    def find_start_P(self, texto_string):\n",
        "        matches = re.findall(r'^\\s*\\(P\\).*', texto_string, re.MULTILINE)\n",
        "        return matches\n",
        "\n",
        "    def find_end_P(self, texto_string):\n",
        "        matches = re.findall(r'^.*\\(P\\)\\s*$', texto_string, re.MULTILINE)\n",
        "        return matches\n",
        "\n",
        "    #! MetodosPandas\n",
        "\n",
        "    def concatenate_dataframes(self, df_list, axis=0, reset_index=True):\n",
        "        \"\"\"\n",
        "        Concatena uma lista de DataFrames ao longo de um eixo especificado.\n",
        "\n",
        "        Parâmetros:\n",
        "        - df_list: Lista de DataFrames para concatenar.\n",
        "        - axis: Eixo ao longo do qual os DataFrames devem ser concatenados.\n",
        "                0 para vertical (default) e 1 para horizontal.\n",
        "        - reset_index: Se True, redefine o índice do DataFrame resultante. Default é True.\n",
        "\n",
        "        Retorna:\n",
        "        - DataFrame concatenado.\n",
        "        \"\"\"\n",
        "        concatenated_df = pd.concat(df_list, axis=axis)\n",
        "\n",
        "        if reset_index and axis == 0:\n",
        "            concatenated_df = concatenated_df.reset_index(drop=True)\n",
        "\n",
        "        return concatenated_df\n",
        "\n",
        "\n",
        "    #! Métodos REGEX\n",
        "    def criar_dataframeSeguranca(self, texto):\n",
        "        data = {}\n",
        "\n",
        "        # Splitting the provided text to find all occurrences of \"Medidas de Segurança\" or \"Medidas de segurança\"\n",
        "        split_text = re.split(r'Medidas de [Ss]egurança:', texto)\n",
        "\n",
        "        for idx, section in enumerate(split_text[1:], start=1):  # skip the 0th index as it's before the first occurrence\n",
        "            # Extracting information until the next occurrence of \"Medidas de Segurança:\" or other stopping patterns\n",
        "            extracted_info = re.search(r'(.*?)(?=\\d{9}|Ações de [Mm]anutenção:|Medidas de [Ss]egurança:|$)', section, re.DOTALL)\n",
        "\n",
        "            if extracted_info:\n",
        "                key = f'Medidas de segurança {idx}' if len(split_text) > 2 else 'Medidas de segurança 1'\n",
        "                data[key] = [extracted_info.group(1).strip()]\n",
        "\n",
        "        # Convert the data dictionary to a DataFrame\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    def criar_dataframeManutencao(self,texto):\n",
        "        data = {}\n",
        "\n",
        "        # Splitting the provided text to find all occurrences of \"Ações de manutenção\"\n",
        "        split_text = texto.split(\"Ações de manutenção:\")\n",
        "\n",
        "        for idx, section in enumerate(split_text[1:], start=1):  # skip the 0th index as it's before the first occurrence\n",
        "            # Extracting information until the next occurrence of \"Ações de manutenção:\" or other stopping patterns\n",
        "            extracted_info = re.search(r'(.*?)(?=\\d{9}|Ações de manutenção:|Medidas de [Ss]egurança:)', section, re.DOTALL)\n",
        "\n",
        "            if extracted_info:\n",
        "                key = f'Ações de manutenção {idx}' if len(split_text) > 2 else 'Ações de manutenção 1'\n",
        "                data[key] = [extracted_info.group(1).strip()]\n",
        "\n",
        "        # Convert the data dictionary to a DataFrame\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    def mostrar_matches(self,texto_string):\n",
        "        \"\"\"\n",
        "        Mostra os matches e os textos extraídos para cada padrão de regex.\n",
        "        \"\"\"\n",
        "\n",
        "        # Padrão de regex para extrair informações\n",
        "        pattern_nome = re.compile(r'(?<=\\dHrs ).+?(?=\\n\\d{10}|\\n\\(|\\n[A-Z])', re.DOTALL)\n",
        "        pattern_numero_tarefa = re.compile(r'^\\d{10}', re.MULTILINE)\n",
        "        pattern_carencia = re.compile(r'(?<=\\d{10} )\\d{1,2}')\n",
        "        pattern_intervalo = re.compile(r'\\d+\\.\\d+(MONTHS|Hours)')\n",
        "        pattern_relogio = re.compile(r'\\d+Hrs')\n",
        "\n",
        "        # Encontrar todas as correspondências no texto\n",
        "        matches_nome = [match.group().replace(\"\\n\", \" \") for match in pattern_nome.finditer(texto_string)]\n",
        "        matches_numero_tarefa = pattern_numero_tarefa.findall(texto_string)\n",
        "        matches_carencia = pattern_carencia.findall(texto_string)\n",
        "        matches_intervalo = pattern_intervalo.findall(texto_string)\n",
        "        matches_relogio = pattern_relogio.findall(texto_string)\n",
        "\n",
        "        # Criando o DataFrame\n",
        "        df = pd.DataFrame({\n",
        "            'Nome Match': matches_nome,\n",
        "            'Número da Tarefa Match': matches_numero_tarefa,\n",
        "            'Intervalo Match': matches_intervalo,\n",
        "            'Carência Match': matches_carencia,\n",
        "            'Relógio Match': matches_relogio\n",
        "        })\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "    def extrair_periodicidade(self, texto_string):\n",
        "        \"\"\"\n",
        "        Extraia informações específicas do texto fornecido e retorne um dicionário com DataFrames\n",
        "        para cada tipo de periodicidade: 'Inspection', 'Drydock', 'Sampling'.\n",
        "        \"\"\"\n",
        "        # Listas para armazenar os dados extraídos\n",
        "        numero_tarefa = []\n",
        "        carencia = []\n",
        "        intervalo = []\n",
        "        relogio = []\n",
        "        nome = []\n",
        "\n",
        "        # Dividindo o texto fornecido em linhas\n",
        "        lines = texto_string.split(\"\\n\")\n",
        "\n",
        "        # Iterando pelas linhas para extrair dados\n",
        "        for i in range(len(lines)):\n",
        "            # Verificar linhas que começam com o padrão de 'Número da Tarefa'\n",
        "            if re.match(r'^\\d{10}', lines[i]):\n",
        "                numero_tarefa.append(re.search(r'^\\d{10}', lines[i]).group())\n",
        "                carencia.append(re.search(r'^\\d{10} (\\d{1,2})', lines[i]).group(1))\n",
        "                intervalo.append(re.search(r'(\\d+\\.\\d+(MONTHS|Hours))', lines[i]).group(1))\n",
        "                relogio.append(re.search(r'(\\d+Hrs)', lines[i]).group(1))\n",
        "                nome.append(lines[i+1] + \" \" + lines[i+2])\n",
        "\n",
        "        # Criando o DataFrame principal\n",
        "        df = pd.DataFrame({\n",
        "            'Nome': nome,\n",
        "            'Número da Tarefa': numero_tarefa,\n",
        "            'Intervalo': intervalo,\n",
        "            'Carência': carencia,\n",
        "            'Relógio': relogio\n",
        "        })\n",
        "\n",
        "        # Criando um dicionário para armazenar os DataFrames para cada tipo de periodicidade\n",
        "        periodicidade_colunas = ['Inspection', 'Drydock', 'Sampling']\n",
        "        df_dict = {}\n",
        "        for periodicidade in periodicidade_colunas:\n",
        "            df_dict[periodicidade] = df[df[\"Nome\"].str.contains(periodicidade)]\n",
        "\n",
        "        return df_dict\n",
        "\n",
        "    def combinar_periodicidade(self, df1, df2, new_names=('Periodicidade 1', 'Periodicidade 2')):\n",
        "        \"\"\"\n",
        "        Renomeia a coluna 'Nome' e concatena dois DataFrames lado a lado.\n",
        "\n",
        "        Parâmetros:\n",
        "        - df1: Primeiro DataFrame.\n",
        "        - df2: Segundo DataFrame.\n",
        "        - new_names: Nomes novos para a coluna 'Nome' em df1 e df2.\n",
        "\n",
        "        Retorna:\n",
        "        - DataFrame resultante da concatenação.\n",
        "        \"\"\"\n",
        "\n",
        "        # Renomeando colunas\n",
        "        df1 = df1.rename(columns={'Nome Match': new_names[0]})\n",
        "        df2 = df2.rename(columns={'Nome Match': new_names[1]})\n",
        "\n",
        "        # Resetando os índices para alinhar os DataFrames corretamente\n",
        "        df1 = df1.reset_index(drop=True)\n",
        "        df2 = df2.reset_index(drop=True)\n",
        "\n",
        "        # Juntando DataFrames lado a lado\n",
        "        combined_df = pd.concat([df1, df2], axis=1)\n",
        "\n",
        "        return combined_df\n",
        "\n",
        "\n",
        "\n",
        "    def consolidate_columns(self,df):\n",
        "        # Identify duplicate columns based on column names\n",
        "        duplicate_columns = df.columns[df.columns.duplicated()].unique()\n",
        "\n",
        "        # Consolidate duplicate columns\n",
        "        for col in duplicate_columns:\n",
        "            # Get all columns with the same name\n",
        "            duplicate_cols = [duplicate_col for duplicate_col in df if duplicate_col == col]\n",
        "\n",
        "            # Combine columns into a single column\n",
        "            combined_col = df[duplicate_cols].apply(lambda row: ''.join(row.dropna().astype(str)), axis=1)\n",
        "\n",
        "            # Drop the original duplicate columns and add the combined column\n",
        "            df = df.drop(columns=duplicate_cols)\n",
        "            df[col] = combined_col\n",
        "\n",
        "        return df\n",
        "\n",
        "    def limpar_dataframe(self, df):\n",
        "        # 1. Drop duplicate columns\n",
        "        df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "        # 2. Drop rows with all NaN values\n",
        "        df = df.dropna(how='all')\n",
        "\n",
        "        # 3. Split multi-entry rows into separate rows\n",
        "        df = self.consolidate_columns(df)\n",
        "\n",
        "        # 4. Reset index for cleanliness\n",
        "        df = df.reset_index(drop=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #! metodos de extrair info\n",
        "    def find_start_index(self, lines, word):\n",
        "        for i in range(len(lines)):\n",
        "            if word in lines[i]:\n",
        "                return i + 1\n",
        "        return -1\n",
        "\n",
        "    def extract_data(self, lines, start_idx):\n",
        "        data = []\n",
        "        i = start_idx\n",
        "        while i < len(lines) and lines[i].strip() != '':\n",
        "            data.append(lines[i])\n",
        "            i += 1\n",
        "        return data\n",
        "\n",
        "    def split_security_measures(self, text):\n",
        "        # Dividir o texto em \"Medidas de segurança\"\n",
        "        # O primeiro elemento será vazio, então nós o ignoramos\n",
        "        sections = re.split(r'Medidas de segurança', text)[1:]\n",
        "\n",
        "        # Para cada seção, obtenha as medidas individuais\n",
        "        all_measures = [re.findall(r'\\d+\\) (.+?)\\.\\n', section)\n",
        "                        for section in sections]\n",
        "\n",
        "        # Transpor a lista para ter cada medida de cada seção em uma lista separada\n",
        "        max_len = max(len(measures) for measures in all_measures)\n",
        "        measures_transposed = []\n",
        "        for i in range(max_len):\n",
        "            row = []\n",
        "            for measures in all_measures:\n",
        "                if i < len(measures):\n",
        "                    row.append(measures[i])\n",
        "                else:\n",
        "                    # Se essa seção tiver menos medidas, adicione None\n",
        "                    row.append(None)\n",
        "            measures_transposed.append(row)\n",
        "\n",
        "        # Converta em DataFrame\n",
        "        df = pd.DataFrame(measures_transposed, columns=[\n",
        "                          f\"Medidas {i+1}\" for i in range(len(all_measures))])\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #!Metodos Excel\n",
        "    def juntar_dataframes(self, list_of_dfs, direcao=1):\n",
        "        \"\"\"\n",
        "        Junta uma lista de DataFrames lado a lado (horizontalmente).\n",
        "        \"\"\"\n",
        "        return pd.concat(list_of_dfs, axis=direcao)\n",
        "\n",
        "    def add_empty_row(self, df):\n",
        "        empty_row = pd.DataFrame([[\"\"] * df.shape[1]], columns=df.columns)\n",
        "        return pd.concat([df, empty_row], ignore_index=True)\n",
        "\n",
        "    def save_to_excel(self, dfs, sheet_names, filename):\n",
        "        \"\"\"\n",
        "        Salva uma lista de DataFrames em um único arquivo Excel com múltiplas abas.\n",
        "\n",
        "        Parameters:\n",
        "        - dfs: Lista de DataFrames\n",
        "        - sheet_names: Lista de nomes para as abas\n",
        "        - filename: Nome do arquivo Excel de saída\n",
        "        \"\"\"\n",
        "        with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "            for df, sheet_name in zip(dfs, sheet_names):\n",
        "                df_with_empty_row = self.add_empty_row(df)\n",
        "                df_with_empty_row.to_excel(\n",
        "                    writer, sheet_name=sheet_name, index=False)\n",
        "        print(f'Arquivo excel salvo: {filename}')\n",
        "\n",
        "    def extrair_nome_aba(self, texto_string):\n",
        "        \"\"\"\n",
        "        Encontra o nome da aba que termina com '(P)' e retorna.\n",
        "        \"\"\"\n",
        "        match = re.search(r'(.+? \\(P\\))', texto_string)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "        else:\n",
        "            return \"DefaultSheetName\"\n",
        "\n",
        "    def nome_arquivo_excel(self, pdf_filename):\n",
        "        \"\"\"\n",
        "        Transforma o nome do arquivo PDF no nome desejado para o arquivo Excel.\n",
        "        \"\"\"\n",
        "        base_name = os.path.basename(\n",
        "            pdf_filename)  # Pega o nome do arquivo sem o caminho\n",
        "        name_without_extension = os.path.splitext(\n",
        "            base_name)[0]  # Remove a extensão\n",
        "        # Transforma \"SJ - SAGITARIUS 2023-07-21\" em \"SAGITARIUS 2023-07-21\"\n",
        "        return name_without_extension.replace(\"SJ - \", \"\") + \".xlsx\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def criar_dataframes_e_periodicidade(dragonite, texto):\n",
        "    \"\"\"Cria DataFrames a partir do texto da página e extrai periodicidade.\"\"\"\n",
        "    colunas = ['Ações de manutenção', 'Medidas de segurança']\n",
        "\n",
        "    array_df = []\n",
        "    periodicidade_array = []\n",
        "\n",
        "    df1 = dragonite.criar_dataframeManutencao(texto)\n",
        "    array_df.append(df1)\n",
        "\n",
        "    df2 = dragonite.criar_dataframeSeguranca(texto)\n",
        "    array_df.append(df2)\n",
        "\n",
        "    try:\n",
        "        df3 = dragonite.extrair_periodicidade(texto)\n",
        "\n",
        "        if df3.empty:\n",
        "            df_test = dragonite.mostrar_matches(texto)\n",
        "            periodicidade_array.append(df_test)\n",
        "\n",
        "        if all(key in df3 for key in ['Inspection', 'Drydock', 'Sampling']):\n",
        "            df_inspection = df3['Inspection']\n",
        "            df_drydock = df3['Drydock']\n",
        "            df_sampling = df3['Sampling']\n",
        "\n",
        "            periodicidade_df = dragonite.combinar_periodicidade(df_inspection, df_drydock)\n",
        "\n",
        "            if periodicidade_df is not None:\n",
        "                array_df.append(periodicidade_df)\n",
        "                print(periodicidade_df)\n",
        "            else:\n",
        "                print('Não foi possível extrair a periodicidade 2')\n",
        "        else:\n",
        "            raise ValueError(\"Chaves necessárias não encontradas em df3\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro: {e}\")\n",
        "\n",
        "    try:\n",
        "        df_test = dragonite.mostrar_matches(texto)\n",
        "        _df1 = df_test.iloc[:2]\n",
        "        _df2 = df_test.iloc[2:]\n",
        "\n",
        "        periodicidade_df = dragonite.combinar_periodicidade(_df1, _df2)\n",
        "        display(periodicidade_df)\n",
        "\n",
        "        periodicidade_array.append(_df1)\n",
        "        periodicidade_array.append(_df2)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro: {e}\")\n",
        "\n",
        "    result_df = dragonite.concatenate_dataframes(array_df, axis=1)\n",
        "    return result_df, periodicidade_array\n",
        "\n"
      ],
      "metadata": {
        "id": "9jqlSgWcPEFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UI"
      ],
      "metadata": {
        "id": "jffJjU5xNdWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pdf_path = './SJ - SAGITARIUS 2023-07-21.pdf'\n",
        "\n",
        "NUMERO_PAGINA = 6\n",
        "PAGINAS_SEPARADAS = [53, 54,64]\n",
        "\n",
        "#Pegando o nome do arquivol\n",
        "fileName = pdf_path.find('SJ')\n",
        "fileName = pdf_path[fileName:]\n",
        "print(fileName)\n",
        "\n",
        "\n",
        "# Instantiate the Dragonite class\n",
        "dragonite = Dragonite(pdf_path)\n",
        "print('\\nTotal de paginas: ',dragonite.number_of_pages)\n",
        "\n",
        "texto = dragonite.ler_pagina(NUMERO_PAGINA)\n",
        "\n",
        "#TODO FAZER UM CHECK SE A PAGINA ESTA COMPLETA\n",
        "def paginasSeparadas():\n",
        "    texto_split = dragonite.ler_intervalo_paginas(PAGINAS_SEPARADAS[0], PAGINAS_SEPARADAS[1])\n",
        "    return texto_split\n",
        "#texto = paginasSeparadas()\n",
        "\n",
        "\n",
        "texto = dragonite.traduzirTexto(texto)\n",
        "\n",
        "print('\\nTEXTO 1:\\n\\n',texto)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO-oRcZMNc4b",
        "outputId": "8b909ec0-84d1-4c42-d458-cf432a592dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SJ - SAGITARIUS 2023-07-21.pdf\n",
            "\n",
            "Total de paginas:  98\n",
            "\n",
            "TEXTO 1:\n",
            "\n",
            " Navio: STARNAV SAGITARIUSPER-SHIP RELATÓRIO DE DESCRIÇÃO DE TRABALHO PADRÃO Impresso em: 21-07-2023\n",
            "Número da\n",
            "TarefaIntervalo Carên\n",
            "ciaRelógio Req Último\n",
            "ConcluídoNúmero da Conta PriCategoria da\n",
            "Nome da TarefaJob\n",
            "Medidas de segurança:\n",
            "1) Parar o equipamento e sinalizar \"Em manutenção, não colocado em serviço\".\n",
            "2) Não permitir que pessoas não autorizadas se aproximem do equipamento enquanto a manutenção estiver sendo realizada.\n",
            "3) Utilização do equipamento pessoal, de acordo com o trabalho realizado.\n",
            "4) Não use roupas largas que possam ficar presas em peças móveis.\n",
            "5) Não utilize ar comprimido para limpeza do corpo, nem equipamento de proteção individual.\n",
            "6) Descartar especificamente os resíduos, evitando poluição do meio ambiente.\n",
            "7) Não acondicione fluidos de manutenção em recipientes de vidro, pois estes podem se quebrar.\n",
            "8) Tomar todos os cuidados com o relacionado a produtos/soluções de limpeza.\n",
            "9) Certifique-se de que todas as linhas de pressão estejam despressurizadas.\n",
            "Ações de manutenção:\n",
            "1) Realizar inspeção visual e de temperatura nos mancais da linha do eixo, devendo permanecer abaixo de 80°C.\n",
            "temperaturas superiores a essa, ocorre operação da graxa e encurtamento da vida útil da graxa e das vedações. Se essa\n",
            "situação ocorrer, ela deverá ser investigada e corrigida.\n",
            "6400020156 3 30-03-2023 510012 D Inspeção 1,0 MESES 0 Horas Conjunto de Rolamento (PRT) 1\n",
            "Inspeção Mensal\n",
            "6400020164 3 30-03-2023 510012 D Inspeção 1,0 MESES 0 Horas Conjunto de Rolamento (STB) 1\n",
            "Inspeção Mensal\n",
            "(P) Inspeção A Cada 3 Meses: Propulsor Azimutal: Conjunto de Rolamento\n",
            "Medidas de segurança:\n",
            "1) Parar o equipamento e sinalizar \"Em manutenção, não colocado em serviço\".\n",
            "2) Não permitir que pessoas não autorizadas se aproximem do equipamento enquanto a manutenção estiver sendo realizada.\n",
            "3) Utilização do equipamento pessoal, de acordo com o trabalho realizado.\n",
            "4) Não use roupas largas que possam ficar presas em peças móveis.\n",
            "5) Não utilize ar comprimido para limpeza do corpo, nem equipamento de proteção individual.\n",
            "6) Descartar especificamente os resíduos, evitando poluição do meio ambiente.\n",
            "7) Não acondicione fluidos de manutenção em recipientes de vidro, pois estes podem se quebrar.\n",
            "8) Tomar todos os cuidados com o relacionado a produtos/soluções de limpeza.\n",
            "9) Certifique-se de que todas as linhas de pressão estejam despressurizadas.\n",
            "Ações de manutenção:\n",
            "1) Realizar inspeção visual, verificar o aperto (torque) dos parafusos das bases e nas tampas dos mancais, corrigindo se\n",
            "necessário. Substitua as travas e marcações de posição final das portas.\n",
            "6400020157 5 30-01-2023 510012 D Inspeção 3,0 MESES 0 Horas Conjunto de Rolamento (PRT) 3\n",
            "Inspeção Mensal\n",
            "6400020165 5 30-01-2023 510012 D Inspeção 3,0 MESES 0 Horas Conjunto de Rolamento (STB) 3\n",
            "Inspeção Mensal\n",
            "(P) SKF Lubricação A Cada 6 Meses: Propulsor Azimutal: Conjunto de Rolamento\n",
            "Medidas de segurança:\n",
            "1) Parar o equipamento e sinalizar \"Em manutenção, não colocado em serviço\".\n",
            "2) Não permitir que pessoas não autorizadas se aproximem do equipamento enquanto a manutenção estiver sendo realizada.\n",
            "CL= Requisitos de Sociedade de Classificação, CG = Requisito da Guarda Costeira Página: 6 de 98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LkLC99rCN87t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}